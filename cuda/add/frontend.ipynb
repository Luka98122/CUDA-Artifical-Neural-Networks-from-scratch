{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBuild command (rtx 4090)\\nnvcc --shared add.cu -o add.dll -Xcompiler \"/MD\" -arch=sm_86\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "from ctypes import c_float, POINTER, c_int\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from numpy.ctypeslib import ndpointer\n",
    "\"\"\"\n",
    "Build command (rtx 4090)\n",
    "nvcc --shared add.cu -o add.dll -Xcompiler \"/MD\" -arch=sm_86\n",
    "\n",
    "OR\n",
    "\n",
    "nvcc --shared add.cu -o add.dll -Xcompiler \"/MD\" -arch=sm_86 -allow-unsupported-compiler\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3e22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook was marking the file as in use\n",
    "# Even when finished processing, so we copy the file\n",
    "# and keep the copy open so we can rebuild to add.dll\n",
    "shutil.copy2(\"./add.dll\",\"./use_add.dll\")\n",
    "lib = ctypes.CDLL(\"./use_add.dll\") \n",
    "rf = ctypes.byref\n",
    "\n",
    "lib.add_cuda.argtypes = [POINTER(c_float), POINTER(c_float), POINTER(c_float)]\n",
    "lib.add_cuda.restype = None\n",
    "\n",
    "lib.multiply_cuda.argtypes = [POINTER(c_float), POINTER(c_float), POINTER(c_float)]\n",
    "lib.multiply_cuda.restype = None\n",
    "\n",
    "lib.mat_add_cuda.argtypes = [\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_int\n",
    "]\n",
    "lib.mat_add_cuda.restype = None\n",
    "\n",
    "lib.dot_product_cuda.argtypes = [POINTER(c_float),POINTER(c_float), POINTER(c_float),c_int]\n",
    "lib.dot_product_cuda.restype = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f636bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from add CUDA: 5.75\n",
      "Result from multiply CUDA: 7.875\n"
     ]
    }
   ],
   "source": [
    "a = c_float(3.5)\n",
    "b = c_float(2.25)\n",
    "result = c_float()\n",
    "\n",
    "lib.add_cuda(rf(a), rf(b), ctypes.byref(result))\n",
    "print(\"Result from add CUDA:\", result.value)\n",
    "\n",
    "lib.multiply_cuda(rf(a), rf(b), ctypes.byref(result))\n",
    "print(\"Result from multiply CUDA:\", result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e32c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 512, 512\n",
    "\n",
    "A = np.random.rand(rows, cols).astype(np.float32)\n",
    "B = np.random.rand(rows, cols).astype(np.float32)\n",
    "C = np.zeros((rows, cols), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae78dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA matrix addition for size 512*512:  0.0019s\n",
      "Python matrix addition for size 512*512:  0.0333s\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "lib.mat_add_cuda(\n",
    "    A.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "    B.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "    C.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "    rows,\n",
    "    cols\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"CUDA matrix addition for size {rows}*{cols}:  {end-s:.4f}s\")\n",
    "\n",
    "mat1 = []\n",
    "mat2 = []\n",
    "mat3 = []\n",
    "for y in range(rows):\n",
    "    mat1.append([])\n",
    "    mat2.append([])\n",
    "    mat3.append([])\n",
    "    for x in range(cols):\n",
    "        mat1[-1].append(random.randrange(0,4))\n",
    "        mat2[-1].append(random.randrange(0,4))\n",
    "s2 = time.time()\n",
    "for y in range(rows):\n",
    "    for x in range(cols):   \n",
    "        mat3.append(mat1[y][x]+mat2[y][x])\n",
    "print(f\"Python matrix addition for size {rows}*{cols}:  {time.time()-s2:.4f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b253f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is contiguous: True\n",
      "a shape: (10240,), a strides: (4,)\n",
      "b is contiguous: True\n",
      "Dot product result: 30720.0\n"
     ]
    }
   ],
   "source": [
    "n = 10240\n",
    "a = np.ones(n, dtype=np.float32)\n",
    "b = np.ones(n, dtype=np.float32) * 3.0\n",
    "a = a.flatten()\n",
    "b = b.flatten()\n",
    "print(f\"a is contiguous: {a.flags['C_CONTIGUOUS']}\")\n",
    "print(f\"a shape: {a.shape}, a strides: {a.strides}\")\n",
    "print(f\"b is contiguous: {b.flags['C_CONTIGUOUS']}\")\n",
    "\n",
    "res = c_float()\n",
    "\n",
    "n = a.size  # number of elements\n",
    "lib.dot_product_cuda(\n",
    "    a.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "    b.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n",
    "    ctypes.byref(res),\n",
    "    c_int(n)\n",
    ")\n",
    "print(\"Dot product result:\", res.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "5f5f9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Binding ---\n",
    "lib.forward_layer_cuda.argtypes = [\n",
    "    POINTER(c_float), # Input vector\n",
    "    POINTER(c_float), # Weight matrix (flattened)\n",
    "    POINTER(c_float), # Bias vector\n",
    "    POINTER(c_float), # Output vector\n",
    "    c_int,            # n_inputs\n",
    "    c_int             # n_outputs\n",
    "]\n",
    "lib.forward_layer_cuda.restype = None\n",
    "\n",
    "# --- Setup Data ---\n",
    "# Layer dimensions: 4 inputs -> 3 outputs\n",
    "n_in = 4\n",
    "n_out = 3\n",
    "\n",
    "# 1. Inputs (x)\n",
    "input_vec = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "\n",
    "# 2. Weights (W) - Matrix of shape (3, 4) flattened\n",
    "# Neuron 0 weights: [0.1, 0.2, 0.3, 0.4]\n",
    "# Neuron 1 weights: [0.5, 0.6, 0.7, 0.8]\n",
    "# Neuron 2 weights: [0.9, 1.0, 1.1, 1.2]\n",
    "weights = np.array([\n",
    "    0.1, 0.2, 0.3, 0.4,\n",
    "    0.5, 0.6, 0.7, 0.8,\n",
    "    0.9, 1.0, 1.1, 1.2\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3. Bias (b)\n",
    "bias = np.array([0.1, 0.2, 0.3], dtype=np.float32)\n",
    "\n",
    "# 4. Output placeholder\n",
    "output_cuda = np.zeros(n_out, dtype=np.float32)\n",
    "\n",
    "# --- Execute CUDA ---\n",
    "print(\"\\n--- Testing Forward Layer ---\")\n",
    "lib.forward_layer_cuda(\n",
    "    input_vec.ctypes.data_as(POINTER(c_float)),\n",
    "    weights.ctypes.data_as(POINTER(c_float)),\n",
    "    bias.ctypes.data_as(POINTER(c_float)),\n",
    "    output_cuda.ctypes.data_as(POINTER(c_float)),\n",
    "    n_in,\n",
    "    n_out\n",
    ")\n",
    "\n",
    "# --- Verify with NumPy ---\n",
    "# Reshape weights for numpy matmul (n_out, n_in)\n",
    "W_mat = weights.reshape(n_out, n_in)\n",
    "# Calculation: y = Wx + b\n",
    "output_numpy = np.dot(W_mat, input_vec) + bias\n",
    "\n",
    "print(f\"CUDA Output:  {output_cuda}\")\n",
    "print(f\"NumPy Output: {output_numpy}\")\n",
    "\n",
    "if np.allclose(output_cuda, output_numpy, atol=1e-5):\n",
    "    print(\"✅ Success: CUDA matches NumPy\")\n",
    "else:\n",
    "    print(\"❌ Error: Results do not match\")"
=======
   "id": "2255517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.argmax_cuda.argtypes = [\n",
    "    ndpointer(np.float32, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.POINTER(ctypes.c_int),\n",
    "    ctypes.c_int,\n",
    "]\n",
    "lib.argmax_cuda.restype = None\n",
    "\n",
    "x = np.array([1.0, 5.0, 3.0, 5.0], dtype=np.float32)\n",
    "\n",
    "idx = ctypes.c_int()\n",
    "lib.argmax_cuda(x, ctypes.byref(idx), x.size)\n",
    "\n",
    "print(\"CUDA argmax:\", idx.value)\n",
    "print(\"NumPy argmax:\", np.argmax(x))"
>>>>>>> ce3f4d2009155ec8feb10f64442ab9afc2918b2b
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
